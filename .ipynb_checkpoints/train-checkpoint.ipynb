{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage import transform\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim  \n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import argparse\n",
    "import random\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "from skimage.util import random_noise\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "import kornia.augmentation.functional as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"./\"\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self,root, datatxt, transform=None, target_transform=None,loader=default_loader):\n",
    "        super(MyDataset,self).__init__()\n",
    "        fh = open(root + datatxt, 'r') \n",
    "        imgs = []     \n",
    "        data = []\n",
    "        label = []\n",
    "        for line in fh:                \n",
    "            line = line.rstrip()       \n",
    "            data.append(line)\n",
    "        for line in range(len(data)-1):\n",
    "            words = data[line].split()  \n",
    "            imgs.append((words[0])) \n",
    "            label.append(int(words[1]))\n",
    "            \n",
    "        \n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.label = torch.LongTensor(label)\n",
    " \n",
    "    # def __getitem__(self, index):    \n",
    "    def __getitem__(self, idx):    \n",
    "        image = Image.open(str(self.imgs[idx]))\n",
    "        # image = image.convert('RGB')\n",
    "        image = image.convert('L')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        label = self.label[idx]\n",
    "        return image, label\n",
    "    def __len__(self): \n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(root='./',datatxt='train.txt', transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#         AddGaussianNoise(0., 0.05)\n",
    "        ]))\n",
    "# trainNew_dataset = MyDataset(root='./',datatxt='train-new.txt', transform=transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "# #         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "# #         AddGaussianNoise(0., 0.05)\n",
    "#         ]))\n",
    "test_dataset = MyDataset(root='./',datatxt='test.txt', transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#         AddGaussianNoise(0., 0.05)\n",
    "        ]))\n",
    "# testNew_dataset = MyDataset(root='./',datatxt='test-new.txt', transform=transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "# #         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "# #         AddGaussianNoise(0., 0.05)\n",
    "#         ]))\n",
    "origin_dataset = MyDataset(root='./',datatxt='origin.txt', transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,)),\n",
    "#         AddGaussianNoise(0., 0.05)\n",
    "        ]))\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True,num_workers=1)\n",
    "# trainNew_loader = DataLoader(dataset=trainNew_dataset, batch_size=64, shuffle=True,num_workers=1)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False,num_workers=1)\n",
    "# testNew_loader = DataLoader(dataset=testNew_dataset, batch_size=64, shuffle=False,num_workers=1)\n",
    "origin_loader = DataLoader(dataset=origin_dataset, batch_size=64, shuffle=False,num_workers=1)\n",
    "# print('num_of_trainData:', len(train_dataset))\n",
    "# print('num_of_trainNewData:', len(trainNew_dataset))\n",
    "# print('num_of_testData:', len(test_dataset))\n",
    "# print('num_of_testNewData:', len(testNew_dataset))\n",
    "# print('num_of_originData:', len(origin_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label： tensor(0) shape: (1, 19, 19)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "idx = 11\n",
    "img = test_dataset[idx][0].numpy()\n",
    "plt.imshow(img[0], cmap = 'gray')\n",
    "plt.imsave('test.png', img[0], cmap = 'gray')\n",
    "# figure, b = plt.subplots()\n",
    "# figure.set_size_inches(0.19, 0.19)\n",
    "plt.axis('off') \n",
    "print('label：',train_dataset[idx][1], 'shape:', img.shape)\n",
    "print(type(img[0]))\n",
    "matplotlib.image.imsave('name.png',img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative:  36885\n",
      "positive:  34546\n"
     ]
    }
   ],
   "source": [
    "positive = 0\n",
    "negative = 0\n",
    "for idx in range(1,71432):\n",
    "    if train_dataset[idx][1].item() == 0:\n",
    "        negative = negative+1\n",
    "    else:\n",
    "        positive = positive+1\n",
    "print('negative: ', negative)\n",
    "print('positive: ', positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaborConvPC(nn.Module):\n",
    "#     def __init__(self, kernel_size, in_channels, num_orientations, num_scales):\n",
    "#         super(GaborConvPC, self).__init__()\n",
    "#         self.sigma1, self.theta1, self.Lambda1, self.psi1, self.gamma1, self.bias1, self.weights1, self.w, self.b = self.generate_parameters(num_orientations*num_scales, in_channels)\n",
    "#         self.sigma2, self.theta2, self.Lambda2, self.psi2, self.gamma2, self.bias2, self.weights2, self.w, self.b = self.generate_parameters(num_orientations*num_scales, in_channels)\n",
    "#         # self.filter1 = self.whole_filter(in_channels, channel1, kernel_size, self.sigma1, self.theta1, self.Lambda1, self.psi1, self.gamma1)\n",
    "#         self.filter_cos = self.whole_filter(in_channels, num_orientations, num_scales, kernel_size, self.sigma1, self.theta1, self.Lambda1, self.psi1, self.gamma1, True)\n",
    "#         self.filter_sin = self.whole_filter(in_channels, num_orientations, num_scales, kernel_size, self.sigma1, self.theta1, self.Lambda1, self.psi1, self.gamma1, False)\n",
    "    \n",
    "            \n",
    "        \n",
    "#         self.fc1 = nn.Linear(1*1*48, 24)\n",
    "#         self.fc2 = nn.Linear(24, 2)\n",
    "\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x_cos = F.conv2d(x, self.filter_cos, bias=self.bias1)\n",
    "#         x_sin = F.conv2d(x, self.filter_sin, bias=self.bias2)\n",
    "#         x_comb = torch.cat((x_cos, x_sin), 2)\n",
    "# #         print(\"ken\",len(x))\n",
    "# #         print(\"x_comb size\", x_comb.size())\n",
    "# #         x_comb = F.max_pool2d(x_comb, 2, 2)\n",
    "# #         x_comb = F.relu(self.conv(x_comb))\n",
    "# #         x_comb = F.max_pool2d(x_comb, 2, 2)\n",
    "# #         bbb = torch.abs(torch.tensor([-1, -2, 3]))\n",
    "#         x_cos = x_cos.view(len(x), 1, 1, 48)\n",
    "#         x_sin = x_sin.view(len(x), 1, 1, 48)\n",
    "#         weighted_cos = (torch.matmul(x_cos, self.weights1)).view(len(x), 1)\n",
    "#         weighted_sin = (torch.matmul(x_sin, self.weights1)).view(len(x), 1)\n",
    "\n",
    "#         numerator = torch.norm(torch.cat([weighted_cos, weighted_sin], 1), dim=1)\n",
    "# #         print(\"numerator\", numerator.size())\n",
    "#         x_comb_norm = torch.norm(x_comb, dim=2)\n",
    "#         x_comb_norm = x_comb_norm.view(len(x), 1, 48)\n",
    "# #         print(\"x_comb_norm\", x_comb_norm.size())\n",
    "#         denominator = torch.matmul(x_comb_norm, torch.abs(self.weights1))\n",
    "#         denominator = denominator.view(len(x))\n",
    "# #         print(\"size:\", numerator.size(), denominator.size())\n",
    "#         pc = numerator / denominator                \n",
    "# #         x_comb = x_comb.view(-1, 1*1*48)\n",
    "# #         x_comb = F.relu(self.fc1(x_comb))\n",
    "# #         x_comb = self.fc2(x_comb)\n",
    "#         return torch.sigmoid(self.w * pc + self.b)\n",
    "\n",
    "\n",
    "#     def generate_parameters(self, dim_out, dim_in):\n",
    "#         sigma = nn.Parameter(torch.randn(1, 1))\n",
    "#         theta = nn.Parameter(torch.randn(1, 1))\n",
    "#         Lambda = nn.Parameter(torch.randn(1, 1))\n",
    "#         psi = nn.Parameter(torch.randn(1, 1))\n",
    "#         gamma = nn.Parameter(torch.randn(1, 1))\n",
    "#         bias = nn.Parameter(torch.randn(dim_out))\n",
    "#         weights = nn.Parameter(torch.randn(1, 48, 1))\n",
    "#         w = nn.Parameter(torch.randn(1, 1))\n",
    "#         b = nn.Parameter(torch.randn(1, 1))\n",
    "#         return sigma, theta, Lambda, psi, gamma, bias, weights, w, b\n",
    "\n",
    "    def __init__(self, kernel_size, in_channels, num_orientations, num_scales):\n",
    "        super(GaborConvPC, self).__init__()\n",
    "        self.sigma, self.theta, self.Lambda, self.psi, self.gamma, self.bias1, self.bias2, self.weights, self.w, self.b = self.generate_parameters(num_orientations*num_scales, in_channels)\n",
    "#         self.sigma2, self.theta2, self.Lambda2, self.psi2, self.gamma2, self.bias2, self.weights2, self.w, self.b = self.generate_parameters(num_orientations*num_scales, in_channels)\n",
    "        # self.filter1 = self.whole_filter(in_channels, channel1, kernel_size, self.sigma1, self.theta1, self.Lambda1, self.psi1, self.gamma1)\n",
    "        self.filter_cos = self.whole_filter(in_channels, num_orientations, num_scales, kernel_size, self.sigma, self.theta, self.Lambda, self.psi, self.gamma, True)\n",
    "        self.filter_sin = self.whole_filter(in_channels, num_orientations, num_scales, kernel_size, self.sigma, self.theta, self.Lambda, self.psi, self.gamma, False)\n",
    "\n",
    "#         self.conv = nn.Conv2d(48, 50, 5, 1)\n",
    "        \n",
    "        self.fc1 = nn.Linear(1*1*48, 24)\n",
    "        self.fc2 = nn.Linear(24, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cos = F.conv2d(x, self.filter_cos, bias=self.bias1)\n",
    "        x_sin = F.conv2d(x, self.filter_sin, bias=self.bias2)\n",
    "        x_comb = torch.cat((x_cos, x_sin), 2)\n",
    "#         print(\"ken\",len(x))\n",
    "#         print(\"x_comb size\", x_comb.size())\n",
    "#         x_comb = F.max_pool2d(x_comb, 2, 2)\n",
    "#         x_comb = F.relu(self.conv(x_comb))\n",
    "#         x_comb = F.max_pool2d(x_comb, 2, 2)\n",
    "#         bbb = torch.abs(torch.tensor([-1, -2, 3]))\n",
    "        x_cos = x_cos.view(len(x), 1, 1, 48)\n",
    "        x_sin = x_sin.view(len(x), 1, 1, 48)\n",
    "        weighted_cos = (torch.matmul(x_cos, self.weights)).view(len(x), 1)\n",
    "        weighted_sin = (torch.matmul(x_sin, self.weights)).view(len(x), 1)\n",
    "\n",
    "        numerator = torch.norm(torch.cat([weighted_cos, weighted_sin], 1), dim=1)\n",
    "#         print(\"numerator\", numerator.size())\n",
    "        x_comb_norm = torch.norm(x_comb, dim=2)\n",
    "        x_comb_norm = x_comb_norm.view(len(x), 1, 48)\n",
    "#         print(\"x_comb_norm\", x_comb_norm.size())\n",
    "        denominator = torch.matmul(x_comb_norm, torch.abs(self.weights))\n",
    "        denominator = denominator.view(len(x))\n",
    "#         print(\"size:\", numerator.size(), denominator.size())\n",
    "        pc = numerator / denominator                \n",
    "#         x_comb = x_comb.view(-1, 1*1*48)\n",
    "#         x_comb = F.relu(self.fc1(x_comb))\n",
    "#         x_comb = self.fc2(x_comb)\n",
    "        return torch.sigmoid(self.w * pc + self.b)\n",
    "\n",
    "\n",
    "    def generate_parameters(self, dim_out, dim_in):\n",
    "        sigma = nn.Parameter(torch.randn(1, 1))\n",
    "        theta = nn.Parameter(torch.randn(1, 1))\n",
    "        Lambda = nn.Parameter(torch.randn(1, 1))\n",
    "        psi = nn.Parameter(torch.randn(1, 1))\n",
    "        gamma = nn.Parameter(torch.randn(1, 1))\n",
    "        bias1 = nn.Parameter(torch.randn(dim_out))\n",
    "        bias2 = nn.Parameter(torch.randn(dim_out))\n",
    "#         bias2 = nn.Parameter(torch.randn(dim_out))\n",
    "        weights = nn.Parameter(torch.randn(1, 48, 1))\n",
    "        w = nn.Parameter(torch.randn(1, 1))\n",
    "        b = nn.Parameter(torch.randn(1, 1))\n",
    "        return sigma, theta, Lambda, psi, gamma, bias1, bias2, weights, w, b\n",
    "\n",
    "\n",
    "    def whole_filter(self, in_channels, num_orientations, num_scales, kernel_size, sigma, theta, Lambda, psi, gamma, cos):\n",
    "        result = torch.zeros(num_orientations*num_scales, in_channels, kernel_size, kernel_size) # \\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kH , kW\n",
    "        for i in range(num_orientations):\n",
    "            for j in range(num_scales):\n",
    "                result[i*num_scales + j] = self.one_filter(in_channels, kernel_size, sigma[0]*(2.1**j), theta[0]+i*np.pi/num_orientations, Lambda[0], psi[0], gamma[0], cos)\n",
    "        return nn.Parameter(result)\n",
    "\n",
    "\n",
    "    def one_filter(self, in_channels, kernel_size, sigma, theta, Lambda, psi, gamma, cos):\n",
    "        result = torch.zeros(in_channels, kernel_size, kernel_size)\n",
    "        for i in range(in_channels):\n",
    "            result[i] = self.gabor_fn(sigma, theta, Lambda, psi, gamma, kernel_size, cos)\n",
    "        return nn.Parameter(result)\n",
    "\n",
    "\n",
    "#     def gabor_fn(self, sigma, theta, Lambda, psi, gamma, kernel_size, cos):\n",
    "#         sigma_x = sigma\n",
    "#         # sigma_y = float(sigma) / gamma\n",
    "#         sigma_y = sigma / gamma\n",
    "\n",
    "#         # Bounding box\n",
    "#         half_size = (kernel_size - 1) // 2\n",
    "#         ymin, xmin = -half_size, -half_size\n",
    "#         ymax, xmax = half_size, half_size\n",
    "#         (x, y) = np.meshgrid(np.arange(xmin, xmax + 1), np.arange(ymin, ymax + 1))\n",
    "#         y = torch.FloatTensor(y)\n",
    "#         x = torch.FloatTensor(x)\n",
    "\n",
    "#         # Rotation\n",
    "#         x_theta = x * torch.cos(theta) + y * torch.sin(theta)\n",
    "#         y_theta = -x * torch.sin(theta) + y * torch.cos(theta)\n",
    "\n",
    "\n",
    "#         if cos:\n",
    "#             gb = torch.exp((-1*(x_theta*x_theta+y_theta*y_theta*gamma*gamma))/(2*sigma*sigma))* torch.cos(2 * np.pi / Lambda * x_theta + psi)\n",
    "#         else:\n",
    "#             gb = torch.exp((-1*(x_theta*x_theta+y_theta*y_theta*gamma*gamma))/(2*sigma*sigma))* torch.sin(2 * np.pi / Lambda * x_theta + psi)\n",
    "#         return gb\n",
    "    def gabor_fn(self, sigma, theta, Lambda, psi, gamma, kernel_size, cos):\n",
    "        sigma_x = sigma\n",
    "        # sigma_y = float(sigma) / gamma\n",
    "        sigma_y = sigma / gamma\n",
    "\n",
    "        # Bounding box\n",
    "        half_size = (kernel_size - 1) // 2\n",
    "        ymin, xmin = -half_size, -half_size\n",
    "        ymax, xmax = half_size, half_size\n",
    "    #     (y, x) = np.meshgrid(np.arange(ymin, ymax + 1), np.arange(xmin, xmax + 1))\n",
    "        y, x = torch.meshgrid([torch.arange(ymin, ymax+1), torch.arange(xmin,xmax+1)])\n",
    "\n",
    "        if cos:\n",
    "            gb = torch.exp(-.5 * (x**2 / sigma_x**2 + y**2 / sigma_y**2)) * torch.cos(2 * np.pi / Lambda * x + psi)\n",
    "        else:\n",
    "            gb = torch.exp(-.5 * (x**2 / sigma_x**2 + y**2 / sigma_y**2)) * torch.sin(2 * np.pi / Lambda * x + psi)\n",
    "\n",
    "        # Rotation\n",
    "        degrees = theta * 180 / np.pi\n",
    "        gb = FF.apply_rotation(gb, {'degrees': torch.tensor(degrees)}, {'interpolation': torch.tensor([1]), 'align_corners': torch.tensor(True)})\n",
    "        gb = gb.squeeze()\n",
    "        return gb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> torch.Size([1, 1])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1])\n",
      "<class 'torch.Tensor'> torch.Size([48])\n",
      "<class 'torch.Tensor'> torch.Size([48])\n",
      "<class 'torch.Tensor'> torch.Size([1, 48, 1])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1])\n",
      "<class 'torch.Tensor'> torch.Size([1, 1])\n",
      "<class 'torch.Tensor'> torch.Size([48, 1, 19, 19])\n",
      "<class 'torch.Tensor'> torch.Size([48, 1, 19, 19])\n",
      "<class 'torch.Tensor'> torch.Size([24, 48])\n",
      "<class 'torch.Tensor'> torch.Size([24])\n",
      "<class 'torch.Tensor'> torch.Size([2, 24])\n",
      "<class 'torch.Tensor'> torch.Size([2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/71432 (0%)]\tLoss: 48.603153\n",
      "Train Epoch: 1 [6400/71432 (9%)]\tLoss: 35.009838\n",
      "Train Epoch: 1 [12800/71432 (18%)]\tLoss: 20.915850\n",
      "Train Epoch: 1 [19200/71432 (27%)]\tLoss: 18.323053\n",
      "Train Epoch: 1 [25600/71432 (36%)]\tLoss: 14.125262\n",
      "Train Epoch: 1 [32000/71432 (45%)]\tLoss: 12.656539\n",
      "Train Epoch: 1 [38400/71432 (54%)]\tLoss: 17.845667\n",
      "Train Epoch: 1 [44800/71432 (63%)]\tLoss: 16.184490\n",
      "Train Epoch: 1 [51200/71432 (72%)]\tLoss: 18.283365\n",
      "Train Epoch: 1 [57600/71432 (81%)]\tLoss: 15.357291\n",
      "Train Epoch: 1 [64000/71432 (90%)]\tLoss: 9.544128\n",
      "Train Epoch: 1 [70400/71432 (98%)]\tLoss: 12.535745\n",
      "\n",
      "Test set: Average loss: 0.2239, Accuracy: 7435/8141 (91%), Positive accuracy: 3558/4091 (87%), Negative accuracy: 3877/4050 (96%)\n",
      "\n",
      "Train Epoch: 2 [0/71432 (0%)]\tLoss: 14.142234\n",
      "Train Epoch: 2 [6400/71432 (9%)]\tLoss: 17.528366\n",
      "Train Epoch: 2 [12800/71432 (18%)]\tLoss: 19.495396\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4c4b4481d3f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-4c4b4481d3f7>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# for param in model.parameters():\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-4c4b4481d3f7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    939\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 941\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    942\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def myLoss(output, target):\n",
    "#     print(\"size,size:\",output.size(), target.size())\n",
    "#     print(\"size,\", ((1-2*target) * torch.log(output)).size())\n",
    "#     return -torch.sum(target * torch.log(output) + (1-target) * torch.log(1-output)) / len(output)\n",
    "    return -torch.sum((36885/34546)*target * torch.log(output) + (1-target) * torch.log(1-output)) / len(output)\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "#         loss = F.nll_loss(output, target)\n",
    "        loss = myLoss(output, target)\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(args, model, device, test_loader,count,epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    result= [[0,0], [0,0]] \n",
    "    with torch.no_grad():\n",
    "        for batch_idx,(data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "#             test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n",
    "            test_loss += myLoss(output, target)\n",
    "#             pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n",
    "            t = Variable(torch.Tensor([0.5]))\n",
    "            pred = (output > t) * 1\n",
    "            pred = torch.reshape(pred, (len(target), 1))\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            cmat = confusion_matrix(target.view_as(pred), pred, labels=[0, 1]) \n",
    "            result = [[result[i][j] + cmat[i][j]  for j in range(len(result[0]))] for i in range(len(result))] \n",
    "             # Store wrongly predicted images\n",
    "            if epoch == 9:\n",
    "                wrong_idx = (pred != target.view_as(pred)).nonzero()[:, 0]\n",
    "                wrong_samples = data[wrong_idx]\n",
    "                wrong_preds = pred[wrong_idx]\n",
    "                actual_preds = target.view_as(pred)[wrong_idx]\n",
    "                for i in range(len(wrong_idx)):\n",
    "                    sample = wrong_samples[i]\n",
    "                    wrong_pred = wrong_preds[i]\n",
    "                    actual_pred = actual_preds[i]\n",
    "                    # Undo normalization\n",
    "            #         sample = sample * 0.3081\n",
    "            #         sample = sample + 0.1307\n",
    "                    sample = sample * 255.\n",
    "                    sample = sample.byte()\n",
    "                    img = TF.to_pil_image(sample)\n",
    "                    count = count+1\n",
    "                    img.save('./wrong-gabor/batch{}_i{}_actual{}_pc{:.4f}.png'.format(\n",
    "                    batch_idx,wrong_idx[i], actual_pred.item(),output[1][wrong_idx[i]]))\n",
    "                    num = batch_idx * 64 + wrong_idx[i]\n",
    "    #                 print(batch_idx,wrong_idx[i])\n",
    "                    img_ori = origin_dataset[num][0].numpy()\n",
    "                    plt.imsave('./wrong-gabor/batch{}_i{}_actual{}_ori.png'.format(\n",
    "                    batch_idx,wrong_idx[i], actual_pred.item()), img_ori[0], cmap = 'gray')\n",
    "            \n",
    "                \n",
    "                    \n",
    "                \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Positive accuracy: {}/{} ({:.0f}%), Negative accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset), \n",
    "        result[1][1],result[1][1]+result[1][0],100. * result[1][1]/(result[1][1]+result[1][0]),\n",
    "        result[0][0],result[0][0]+result[0][1],100. * result[0][0]/(result[0][0]+result[0][1])))\n",
    "    \n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=512, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 10)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 0.01)')\n",
    "    parser.add_argument('--momentum', type=float, default=0.5, metavar='M',\n",
    "                        help='SGD momentum (default: 0.5)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=True,\n",
    "                        help='For Saving the current Model')\n",
    "    parser.add_argument('--std', type=float, default=0, metavar='STD',\n",
    "                        help='noise-std (default: 0)')\n",
    "    parser.add_argument('--mean', type=float, default=0, metavar='MEAN',\n",
    "                        help='noise-std (default: 0)')\n",
    "#     args = parser.parse_args()\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "#     transform=transforms.Compose([\n",
    "#         transforms.ToTensor(),\n",
    "#         transforms.Normalize((0.1307,), (0.3081,))\n",
    "#         ])\n",
    "    model = GaborConvPC(19, 1, 8, 6).to(device)\n",
    "    # if torch.cuda.is_available():\n",
    "    #     torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum)\n",
    "    count = 0\n",
    "    for param in model.parameters():\n",
    "        print(type(param.data), param.size())\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(args, model, device, test_loader,count,epoch)\n",
    "        # for param in model.parameters():\n",
    "        #     print(param.size(), param.data)\n",
    "        # print(model.state_dict())\n",
    "#         if epoch == 9:\n",
    "#             print(model.sigma1, model.theta1,model.Lambda1, model.psi1, model.gamma1)\n",
    "#             scale = 0\n",
    "#             ori = 0\n",
    "#             for i in range(len(model.filter_cos)):\n",
    "# #                 sample = model.filter_cos[i]\n",
    "# #                 print('ori' , sample)\n",
    "# #                 sample = sample * 255.\n",
    "# #                 print('first' , sample)\n",
    "# #                 sample = sample.byte()\n",
    "# #                 print('second' , sample)\n",
    "# #                 img = TF.to_pil_image(sample)\n",
    "#                 figure, b = plt.subplots()\n",
    "#                 figure.set_size_inches(19, 19)\n",
    "#                 plt.axis('off')\n",
    "#                 plt.imshow(model.filter_cos[i].detach().numpy()[0], cmap='gray')\n",
    "# #                 np.savetxt('train-coeff.txt', model.filter_cos[i].detach().numpy()[0], delimiter='    ',fmt='%1.2f')\n",
    "# #                 img.save('./filter/{}_ori_{}scale_{}.png'.format('cos',ori,scale))\n",
    "#                 si = model.sigma1.detach().numpy()*(2.1**scale)\n",
    "#                 de = model.theta1.detach().numpy()+ori*np.pi/8\n",
    "#                 plt.savefig(\"./filter-11.3_9/%s_scale_%.2fdeg_%.2f.png\" % ('cos',si,de), dpi=1,pad_inches=0.0,bbox_inches='tight')\n",
    "#                 if scale == 5:\n",
    "#                     scale = 0\n",
    "#                     ori = ori+1\n",
    "#                 else:\n",
    "#                     scale = scale + 1\n",
    "\n",
    "#             scale = 0\n",
    "#             ori = 0\n",
    "#             for i in range(len(model.filter_sin)):\n",
    "# #                 sample = model.filter_sin[i]\n",
    "# #                 sample = sample * 255.\n",
    "# #                 sample = sample.byte()\n",
    "# #                 img = TF.to_pil_image(sample)\n",
    "#                 figure, b = plt.subplots()\n",
    "#                 figure.set_size_inches(0.19, 0.19)\n",
    "#                 plt.axis('off')\n",
    "#                 plt.imshow(model.filter_sin[i].detach().numpy()[0], cmap='gray')\n",
    "# #                 np.savetxt('train-coeff.txt', model.filter_sin[i].detach().numpy()[0], delimiter='    ',fmt='%1.2f')\n",
    "#                 si = model.sigma1.detach().numpy()*(2.1**scale)\n",
    "#                 de = model.theta1.detach().numpy()+ori*np.pi/8\n",
    "# #                 img.save('./filter/{}_ori_{}scale_{}.png'.ormat('sin',ori,scale))\n",
    "#                 plt.savefig(\"./filter-11.3_9/%s_scale_%.2fdeg_%.2f.png\" % ('sin',si,de), dpi=100,pad_inches=0.0,bbox_inches='tight')\n",
    "#                 if scale == 5:\n",
    "#                     scale = 0\n",
    "#                     ori = ori + 1\n",
    "#                 else:\n",
    "#                     scale = scale + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    if (args.save_model):\n",
    "        torch.save(model.state_dict(),\"pretrain_gabor.pt\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/71432 (0%)]\tLoss: 0.686289\n",
      "Train Epoch: 1 [6400/71432 (9%)]\tLoss: 0.584539\n",
      "Train Epoch: 1 [12800/71432 (18%)]\tLoss: 0.474190\n",
      "Train Epoch: 1 [19200/71432 (27%)]\tLoss: 0.402076\n",
      "Train Epoch: 1 [25600/71432 (36%)]\tLoss: 0.370735\n",
      "Train Epoch: 1 [32000/71432 (45%)]\tLoss: 0.283491\n",
      "Train Epoch: 1 [38400/71432 (54%)]\tLoss: 0.276498\n",
      "Train Epoch: 1 [44800/71432 (63%)]\tLoss: 0.240855\n",
      "Train Epoch: 1 [51200/71432 (72%)]\tLoss: 0.227262\n",
      "Train Epoch: 1 [57600/71432 (81%)]\tLoss: 0.276971\n",
      "Train Epoch: 1 [64000/71432 (90%)]\tLoss: 0.208923\n",
      "Train Epoch: 1 [70400/71432 (98%)]\tLoss: 0.153050\n",
      "\n",
      "Test set: Average loss: 0.2378, Accuracy: 7417/8088 (92%), Positive accuracy: 3994/4089 (98%), Negative accuracy: 3423/3999 (86%), f1 score: 0.9208\n",
      "\n",
      "Train Epoch: 2 [0/71432 (0%)]\tLoss: 0.306779\n",
      "Train Epoch: 2 [6400/71432 (9%)]\tLoss: 0.264262\n",
      "Train Epoch: 2 [12800/71432 (18%)]\tLoss: 0.205650\n",
      "Train Epoch: 2 [19200/71432 (27%)]\tLoss: 0.160425\n",
      "Train Epoch: 2 [25600/71432 (36%)]\tLoss: 0.156365\n",
      "Train Epoch: 2 [32000/71432 (45%)]\tLoss: 0.180798\n",
      "Train Epoch: 2 [38400/71432 (54%)]\tLoss: 0.126737\n",
      "Train Epoch: 2 [44800/71432 (63%)]\tLoss: 0.138076\n",
      "Train Epoch: 2 [51200/71432 (72%)]\tLoss: 0.173478\n",
      "Train Epoch: 2 [57600/71432 (81%)]\tLoss: 0.150692\n",
      "Train Epoch: 2 [64000/71432 (90%)]\tLoss: 0.121171\n",
      "Train Epoch: 2 [70400/71432 (98%)]\tLoss: 0.202568\n",
      "\n",
      "Test set: Average loss: 0.1517, Accuracy: 7602/8088 (94%), Positive accuracy: 3818/4089 (93%), Negative accuracy: 3784/3999 (95%), f1 score: 0.9399\n",
      "\n",
      "Train Epoch: 3 [0/71432 (0%)]\tLoss: 0.107641\n",
      "Train Epoch: 3 [6400/71432 (9%)]\tLoss: 0.235138\n",
      "Train Epoch: 3 [12800/71432 (18%)]\tLoss: 0.128147\n",
      "Train Epoch: 3 [19200/71432 (27%)]\tLoss: 0.203724\n",
      "Train Epoch: 3 [25600/71432 (36%)]\tLoss: 0.162127\n",
      "Train Epoch: 3 [32000/71432 (45%)]\tLoss: 0.215982\n",
      "Train Epoch: 3 [38400/71432 (54%)]\tLoss: 0.108208\n",
      "Train Epoch: 3 [44800/71432 (63%)]\tLoss: 0.125963\n",
      "Train Epoch: 3 [51200/71432 (72%)]\tLoss: 0.126928\n",
      "Train Epoch: 3 [57600/71432 (81%)]\tLoss: 0.156632\n",
      "Train Epoch: 3 [64000/71432 (90%)]\tLoss: 0.053078\n",
      "Train Epoch: 3 [70400/71432 (98%)]\tLoss: 0.128305\n",
      "\n",
      "Test set: Average loss: 0.1354, Accuracy: 7656/8088 (95%), Positive accuracy: 3811/4089 (93%), Negative accuracy: 3845/3999 (96%), f1 score: 0.9467\n",
      "\n",
      "Train Epoch: 4 [0/71432 (0%)]\tLoss: 0.158918\n",
      "Train Epoch: 4 [6400/71432 (9%)]\tLoss: 0.252679\n",
      "Train Epoch: 4 [12800/71432 (18%)]\tLoss: 0.227230\n",
      "Train Epoch: 4 [19200/71432 (27%)]\tLoss: 0.100309\n",
      "Train Epoch: 4 [25600/71432 (36%)]\tLoss: 0.115615\n",
      "Train Epoch: 4 [32000/71432 (45%)]\tLoss: 0.141022\n",
      "Train Epoch: 4 [38400/71432 (54%)]\tLoss: 0.178032\n",
      "Train Epoch: 4 [44800/71432 (63%)]\tLoss: 0.290658\n",
      "Train Epoch: 4 [51200/71432 (72%)]\tLoss: 0.114293\n",
      "Train Epoch: 4 [57600/71432 (81%)]\tLoss: 0.101289\n",
      "Train Epoch: 4 [64000/71432 (90%)]\tLoss: 0.106041\n",
      "Train Epoch: 4 [70400/71432 (98%)]\tLoss: 0.110214\n",
      "\n",
      "Test set: Average loss: 0.1279, Accuracy: 7674/8088 (95%), Positive accuracy: 3860/4089 (94%), Negative accuracy: 3814/3999 (95%), f1 score: 0.9488\n",
      "\n",
      "Train Epoch: 5 [0/71432 (0%)]\tLoss: 0.185372\n",
      "Train Epoch: 5 [6400/71432 (9%)]\tLoss: 0.085135\n",
      "Train Epoch: 5 [12800/71432 (18%)]\tLoss: 0.127880\n",
      "Train Epoch: 5 [19200/71432 (27%)]\tLoss: 0.158869\n",
      "Train Epoch: 5 [25600/71432 (36%)]\tLoss: 0.210791\n",
      "Train Epoch: 5 [32000/71432 (45%)]\tLoss: 0.144909\n",
      "Train Epoch: 5 [38400/71432 (54%)]\tLoss: 0.069924\n",
      "Train Epoch: 5 [44800/71432 (63%)]\tLoss: 0.142672\n",
      "Train Epoch: 5 [51200/71432 (72%)]\tLoss: 0.096306\n",
      "Train Epoch: 5 [57600/71432 (81%)]\tLoss: 0.134781\n",
      "Train Epoch: 5 [64000/71432 (90%)]\tLoss: 0.125714\n",
      "Train Epoch: 5 [70400/71432 (98%)]\tLoss: 0.172395\n",
      "\n",
      "Test set: Average loss: 0.1262, Accuracy: 7679/8088 (95%), Positive accuracy: 3842/4089 (94%), Negative accuracy: 3837/3999 (96%), f1 score: 0.9494\n",
      "\n",
      "Train Epoch: 6 [0/71432 (0%)]\tLoss: 0.087083\n",
      "Train Epoch: 6 [6400/71432 (9%)]\tLoss: 0.131398\n",
      "Train Epoch: 6 [12800/71432 (18%)]\tLoss: 0.287779\n",
      "Train Epoch: 6 [19200/71432 (27%)]\tLoss: 0.132143\n",
      "Train Epoch: 6 [25600/71432 (36%)]\tLoss: 0.156555\n",
      "Train Epoch: 6 [32000/71432 (45%)]\tLoss: 0.119576\n",
      "Train Epoch: 6 [38400/71432 (54%)]\tLoss: 0.121874\n",
      "Train Epoch: 6 [44800/71432 (63%)]\tLoss: 0.167545\n",
      "Train Epoch: 6 [51200/71432 (72%)]\tLoss: 0.176197\n",
      "Train Epoch: 6 [57600/71432 (81%)]\tLoss: 0.227576\n",
      "Train Epoch: 6 [64000/71432 (90%)]\tLoss: 0.104923\n",
      "Train Epoch: 6 [70400/71432 (98%)]\tLoss: 0.109498\n",
      "\n",
      "Test set: Average loss: 0.1250, Accuracy: 7680/8088 (95%), Positive accuracy: 3844/4089 (94%), Negative accuracy: 3836/3999 (96%), f1 score: 0.9495\n",
      "\n",
      "Train Epoch: 7 [0/71432 (0%)]\tLoss: 0.147445\n",
      "Train Epoch: 7 [6400/71432 (9%)]\tLoss: 0.206670\n",
      "Train Epoch: 7 [12800/71432 (18%)]\tLoss: 0.134987\n",
      "Train Epoch: 7 [19200/71432 (27%)]\tLoss: 0.074297\n",
      "Train Epoch: 7 [25600/71432 (36%)]\tLoss: 0.147034\n",
      "Train Epoch: 7 [32000/71432 (45%)]\tLoss: 0.149783\n",
      "Train Epoch: 7 [38400/71432 (54%)]\tLoss: 0.205586\n",
      "Train Epoch: 7 [44800/71432 (63%)]\tLoss: 0.196665\n",
      "Train Epoch: 7 [51200/71432 (72%)]\tLoss: 0.247269\n",
      "Train Epoch: 7 [57600/71432 (81%)]\tLoss: 0.100390\n",
      "Train Epoch: 7 [64000/71432 (90%)]\tLoss: 0.190502\n",
      "Train Epoch: 7 [70400/71432 (98%)]\tLoss: 0.096243\n",
      "\n",
      "Test set: Average loss: 0.1237, Accuracy: 7695/8088 (95%), Positive accuracy: 3856/4089 (94%), Negative accuracy: 3839/3999 (96%), f1 score: 0.9514\n",
      "\n",
      "Train Epoch: 8 [0/71432 (0%)]\tLoss: 0.054252\n",
      "Train Epoch: 8 [6400/71432 (9%)]\tLoss: 0.052768\n",
      "Train Epoch: 8 [12800/71432 (18%)]\tLoss: 0.245263\n",
      "Train Epoch: 8 [19200/71432 (27%)]\tLoss: 0.087221\n",
      "Train Epoch: 8 [25600/71432 (36%)]\tLoss: 0.089640\n",
      "Train Epoch: 8 [32000/71432 (45%)]\tLoss: 0.080708\n",
      "Train Epoch: 8 [38400/71432 (54%)]\tLoss: 0.144052\n",
      "Train Epoch: 8 [44800/71432 (63%)]\tLoss: 0.162243\n",
      "Train Epoch: 8 [51200/71432 (72%)]\tLoss: 0.069508\n",
      "Train Epoch: 8 [57600/71432 (81%)]\tLoss: 0.155029\n",
      "Train Epoch: 8 [64000/71432 (90%)]\tLoss: 0.041488\n",
      "Train Epoch: 8 [70400/71432 (98%)]\tLoss: 0.172628\n",
      "\n",
      "Test set: Average loss: 0.1225, Accuracy: 7699/8088 (95%), Positive accuracy: 3855/4089 (94%), Negative accuracy: 3844/3999 (96%), f1 score: 0.9519\n",
      "\n",
      "Train Epoch: 9 [0/71432 (0%)]\tLoss: 0.103439\n",
      "Train Epoch: 9 [6400/71432 (9%)]\tLoss: 0.136333\n",
      "Train Epoch: 9 [12800/71432 (18%)]\tLoss: 0.149887\n",
      "Train Epoch: 9 [19200/71432 (27%)]\tLoss: 0.100077\n",
      "Train Epoch: 9 [25600/71432 (36%)]\tLoss: 0.143791\n",
      "Train Epoch: 9 [32000/71432 (45%)]\tLoss: 0.121495\n",
      "Train Epoch: 9 [38400/71432 (54%)]\tLoss: 0.138766\n",
      "Train Epoch: 9 [44800/71432 (63%)]\tLoss: 0.102929\n",
      "Train Epoch: 9 [51200/71432 (72%)]\tLoss: 0.145071\n",
      "Train Epoch: 9 [57600/71432 (81%)]\tLoss: 0.195021\n",
      "Train Epoch: 9 [64000/71432 (90%)]\tLoss: 0.181146\n",
      "Train Epoch: 9 [70400/71432 (98%)]\tLoss: 0.075097\n",
      "\n",
      "Test set: Average loss: 0.1233, Accuracy: 7689/8088 (95%), Positive accuracy: 3836/4089 (94%), Negative accuracy: 3853/3999 (96%), f1 score: 0.9507\n",
      "\n",
      "Train Epoch: 10 [0/71432 (0%)]\tLoss: 0.123124\n",
      "Train Epoch: 10 [6400/71432 (9%)]\tLoss: 0.100082\n",
      "Train Epoch: 10 [12800/71432 (18%)]\tLoss: 0.119675\n",
      "Train Epoch: 10 [19200/71432 (27%)]\tLoss: 0.063766\n",
      "Train Epoch: 10 [25600/71432 (36%)]\tLoss: 0.073675\n",
      "Train Epoch: 10 [32000/71432 (45%)]\tLoss: 0.130049\n",
      "Train Epoch: 10 [38400/71432 (54%)]\tLoss: 0.164081\n",
      "Train Epoch: 10 [44800/71432 (63%)]\tLoss: 0.108695\n",
      "Train Epoch: 10 [51200/71432 (72%)]\tLoss: 0.214375\n",
      "Train Epoch: 10 [57600/71432 (81%)]\tLoss: 0.189647\n",
      "Train Epoch: 10 [64000/71432 (90%)]\tLoss: 0.082962\n",
      "Train Epoch: 10 [70400/71432 (98%)]\tLoss: 0.106272\n",
      "\n",
      "Test set: Average loss: 0.1226, Accuracy: 7693/8088 (95%), Positive accuracy: 3844/4089 (94%), Negative accuracy: 3849/3999 (96%), f1 score: 0.9512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.fc1 = nn.Linear(3136, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2)\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x_conv1 = F.relu(x)\n",
    "#         x_temp = self.conv2(x_conv1)\n",
    "#         x_conv2 = F.relu(x_temp)\n",
    "#         x_conv2 = F.max_pool2d(x_conv2, 2)\n",
    "#         print(x_conv2.shape)\n",
    "#         x_conv1 = torch.flatten(x_conv1, 1)\n",
    "#         x_conv2 = torch.flatten(x_conv2, 1)\n",
    "#         x_concat = torch.cat((x_conv1, x_conv2), 1)\n",
    "#         x = self.fc1(x_concat)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.fc2(x)\n",
    "#         output = F.log_softmax(x, dim=1)\n",
    "#         return output\n",
    "    def forward(self, x_ori):\n",
    "        x = self.conv1(x_ori)\n",
    "        conv1 = F.relu(x)  #store conv1\n",
    "        conv2 = self.conv2(conv1)\n",
    "        conv2 = F.relu(conv2) #store conv2\n",
    "        x = F.max_pool2d(conv2, 2)\n",
    "#         x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output,x_ori,conv1,conv2\n",
    "\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    num = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        weight = torch.tensor([34546/(36885+34546),36885/(36885+34546)])\n",
    "        loss = F.nll_loss(output[0], target, weight = weight)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch == 3 and batch_idx == 10:\n",
    "            for i in range(64):\n",
    "                img_ori = output[1][i].numpy()\n",
    "                real = target[i].detach().numpy()\n",
    "                predict = output[0][i].detach().numpy()\n",
    "                plt.imsave('./CNN/real{}_{}_a.png'.format(real,num),img_ori[0],cmap = 'gray')\n",
    "                img_conv1 = output[2][i].detach().numpy()\n",
    "                for j in range(len(img_conv1)):\n",
    "                    plt.imsave('./CNN/real{}_{}_conv1_{}.png'.format(real, num, j),img_conv1[0],cmap = 'gray')\n",
    "                img_conv2 = output[3][i].detach().numpy()\n",
    "                for k in range(len(img_conv2)):\n",
    "                    plt.imsave('./CNN/real{}_{}_conv2_{}.png'.format(real,num,k),img_conv2[0],cmap = 'gray')\n",
    "                num = num+1\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "        \n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} '.format(\n",
    "#                 epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "            if args.dry_run:\n",
    "                break\n",
    "                \n",
    "\n",
    "\n",
    "def test(model, device, test_loader,count,epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    result= [[0,0], [0,0]] \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output[0], target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output[0].argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            cmat = confusion_matrix(target.view_as(pred), pred, labels=[0, 1]) \n",
    "            result = [[result[i][j] + cmat[i][j]  for j in range(len(result[0]))] for i in range(len(result))] \n",
    "            \n",
    "            # Store wrongly predicted images\n",
    "            wrong_idx = (pred != target.view_as(pred)).nonzero()[:, 0]\n",
    "            wrong_samples = data[wrong_idx]\n",
    "            wrong_preds = pred[wrong_idx]\n",
    "            actual_preds = target.view_as(pred)[wrong_idx]\n",
    "            for i in range(len(wrong_idx)):\n",
    "                sample = wrong_samples[i]\n",
    "                wrong_pred = wrong_preds[i]\n",
    "                actual_pred = actual_preds[i]\n",
    "                # Undo normalization\n",
    "        #         sample = sample * 0.3081\n",
    "        #         sample = sample + 0.1307\n",
    "                sample = sample * 255.\n",
    "                sample = sample.byte()\n",
    "                img = TF.to_pil_image(sample)\n",
    "                count = count+1\n",
    "                img.save('./wrong/epoch{}_batch{}_idx{}_actual{}.png'.format(\n",
    "                epoch,batch_idx,wrong_idx[i], actual_pred.item()))\n",
    "                num = batch_idx * 64 + wrong_idx[i]\n",
    "                img_ori = origin_dataset[num][0].numpy()\n",
    "                plt.imsave('./wrong/epoch{}_batch{}_idx{}_actual{}_ori.png'.format(\n",
    "                epoch,batch_idx,wrong_idx[i], actual_pred.item()), img_ori[0], cmap = 'gray')\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    precision = result[1][1]/(result[1][1]+result[0][1])\n",
    "    recall = result[0][0]/(result[0][0]+result[1][0])\n",
    "    f1score = 2*(precision*recall)/(precision+recall)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%), Positive accuracy: {}/{} ({:.0f}%), Negative accuracy: {}/{} ({:.0f}%), f1 score: {:.4f}\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset), \n",
    "        result[1][1],result[1][1]+result[1][0],100. * result[1][1]/(result[1][1]+result[1][0]),\n",
    "        result[0][0],result[0][0]+result[0][1],100. * result[0][0]/(result[0][0]+result[0][1]),f1score))\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--lr', type=float, default=0.01, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=False,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--dry-run', action='store_true', default=False,\n",
    "                        help='quickly check a single pass')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=100, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "    args, unknown = parser.parse_known_args()\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'batch_size': args.batch_size}\n",
    "    if use_cuda:\n",
    "        kwargs.update({'num_workers': 1,\n",
    "                       'pin_memory': True,\n",
    "                       'shuffle': True},\n",
    "                     )\n",
    "\n",
    "    model = Net().to(device)\n",
    "    optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "    count = 0\n",
    "    scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch)\n",
    "        test(model, device, test_loader, count, epoch)\n",
    "        scheduler.step()\n",
    "\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), \"mnist_cnn.pt\")\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
